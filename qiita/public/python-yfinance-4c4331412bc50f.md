---
title: æ—¥æœ¬æ ª3700ç¤¾ä»¥ä¸Šã‚’åˆ†æã€‚yfinance xã€Œã‚ãŒæŠ•è³‡è¡“ã€æ ªå¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚¢ãƒ—ãƒªã‚’ä½œã£ãŸè©±ï¼ˆãƒã‚¤ãƒ–ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼‰
published_at: '2025-10-27 11:30'
private: false
tags:
  - python
  - yfinance
  - react
  - docker
  - githubactions
updated_at: '2025-10-25T06:22:17.202Z'
id: null
organization_url_name: null
slide: false
---

# ã¯ã˜ã‚ã«/ä½œã£ãŸã‚ã‘

:::note
**ãƒã‚¤ãƒ–ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ä½œã£ãŸã‚¢ãƒ—ãƒªã®è¨˜äº‹ã«ãªã‚Šã¾ã™**
:::

ã„ããªã‚Šã§ã™ãŒã€‚
æµ·å¤–æ—…è¡Œã—ãŸã‚Šåƒãå§‹ã‚ãŸã‚Šã™ã‚‹ã¨ã€æ—¥æœ¬ã®è‰¯ã•ãŒèº«ã«æŸ“ã¿ãŸã¨æ„Ÿã˜ãŸäººã¯å¤šã„ã‚“ã˜ã‚ƒãªã„ã§ã—ã‚‡ã†ã‹ï¼Ÿ
ãªã‚“ã‹ã¨ã‚Šã‚ãˆãšå¤–ã§åƒã„ã¦ã¿ãŸã„ã¨æ€ã£ã¦ã„ã¾ã—ãŸãŒã€ä»Šã¯ã„ã¤æˆ»ã‚‹ã‹ã¨è€ƒãˆã‚‹æ—¥ã€…ã§ã™ã€‚ï¼ˆã¨ã«ã‹ãæ¸©æ³‰ã«å…¥ã‚ŠãŸã„ï¼‰

ã¾ãŸè‰²ã€…ã¨å„å›½ã‚’å›ã‚‹ä¸­ã§ã€æ—¥æœ¬ä¼æ¥­ã£ã¦ã‚¢ã‚¸ã‚¢åœã‚„ä»–ã®å›½ã«ã‚‚ã‹ãªã‚Šé€²å‡ºã—ã¦ã‚‹ã‚“ã ãªãã¨å®Ÿæ„Ÿã—ã¾ã—ãŸã€‚ï¼ˆãã‚Šã‚ƒãã†ï¼‰

ãã‚“ãªã“ã‚“ãªã§æ—¥æœ¬æ ªã«èˆˆå‘³ã‚’æŒã¡
æ˜¨å¹´ã«[ã‚ãŒæŠ•è³‡è¡“](https://amzn.to/3IEVRkq)ã‚’è³¼å…¥ã—ã¦å®Ÿè·µã—å§‹ã‚ã¾ã—ãŸã€‚ï¼ˆã¾ã åˆã‚ã¦ä¸€å¹´ç›®ãªã®ã§æˆç¸¾ã¯ã‚ã‹ã‚Šã¾ã›ã‚“ã€‚ã€‚ã€‚ãŒã€ãƒã‚¤ãƒŠã‚¹ã¯ç„¡ã—ï¼‰

è‡ªåˆ†ã§ãƒãƒ•ã‚§ãƒƒãƒˆã‚³ãƒ¼ãƒ‰ã‚„ `Claude mcp-yfinance` ãªã©ã‚’åˆ©ç”¨ã—ãªãŒã‚‰ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã¿ã¾ã—ãŸãŒã€æ¯å›æ±ºç®—ãŒå‡ºã‚‹ãŸã³ã«æ‰‹å‹•ã¨ãƒãƒ£ãƒƒãƒˆç›¸æ‰‹ã«ã‚ã‚‹ã®ã‚‚ä½•ã‹ãªãã€‚ã¨æ€ã„ã¾ã—ã¦ã€‚

ã˜ã‚ƒã‚è‡ªå‹•åé›†ã¨ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã®ã‚¢ãƒ—ãƒªä½œã£ã¦ã¿ã‚ˆã†(vibe coding)

ãã‚“ãªãƒãƒªã‹ã‚‰ã€**æ—¥æœ¬æ ªå…¨éŠ˜æŸ„ã‚’è‡ªå‹•åé›†ãƒ»ç°¡æ˜“ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã§ãã‚‹ Web ã‚¢ãƒ—ãƒª**ã‚’é–‹ç™ºã—ã¾ã—ãŸã€‚
â€»ç¾çŠ¶ã€å–å¾—ãƒ‡ãƒ¼ã‚¿ã®æ¬ æãªã©ãŒè¦‹ã‚‰ã‚Œã‚‹ã¨ã“ã¨ãŒã‚ã‚Šã¾ã™ãŒã€æš–ã‹ãè¦‹å®ˆã£ã¦ã„ãŸã ã‘ã‚‹ã¨å¹¸ã„ã§ã™ã€‚

ã“ã®è¨˜äº‹ã§ã¯ã€ç²—æ–¹ã®æ§‹æˆã¨ã€å®Ÿéš›ã«ãƒ­ãƒ¼ã‚«ãƒ«ã§ã“ã‚Œã‚’è©¦ã™æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚
ç´°ã‹ã„ã‚³ãƒ¼ãƒ‰ãªã©ã¯ãã“ã¾ã§æœŸå¾…ã—ãªã„ã§ãã ã•ã„ ğŸ˜…

## ä½œã£ãŸã‚‚ã®

### ğŸ“Š [yfinance-jp-screener](https://github.com/testkun08080/yfinance-jp-screener)

<!-- ![ã‚µãƒ³ãƒ—ãƒ«](https://raw.githubusercontent.com/testkun08080/zenn-docs/main/images/python-yfinance-4c4331412bc50f/img_sample.png) -->

![ã‚µãƒ³ãƒ—ãƒ«2](https://raw.githubusercontent.com/testkun08080/zenn-docs/main/images/python-yfinance-4c4331412bc50f/img_sample2.png)
_CSV ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã¨æ¤œç´¢éƒ¨åˆ†_
![æ¤œç´¢çµæœ](https://raw.githubusercontent.com/testkun08080/zenn-docs/main/images/python-yfinance-4c4331412bc50f/search_result.png)
_æ¤œç´¢çµæœ(ä¼æ¥­åã¯ã“ã“ã§ã¯ä¼ã›ã¦ãŠãã¾ã™)_

**ä¸»ãªæ©Ÿèƒ½:**

- ğŸ“ˆ JPX å…¬å¼ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç´„ 3,795 éŠ˜æŸ„ã‚’è‡ªå‹•å–å¾—
- ğŸ” è²¡å‹™æŒ‡æ¨™ã«ã‚ˆã‚‹é«˜é€Ÿã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
- ğŸ“Š PBRã€ROEã€è‡ªå·±è³‡æœ¬æ¯”ç‡ãªã©ã®æŒ‡æ¨™å¯è¦–åŒ–
- âš™ï¸ GitHub Actions ã«ã‚ˆã‚‹è‡ªå‹•ãƒ‡ãƒ¼ã‚¿åé›†
- ğŸ³ Docker ç°¡å˜ãƒ‡ãƒ—ãƒ­ã‚¤

# ã€Œã‚ãŒæŠ•è³‡è¡“ã€ã¨ã®å‡ºä¼šã„

[ã‚ãŒæŠ•è³‡è¡“](https://amzn.to/3IEVRkq)ã§ã¯ã€**ã‚·ãƒ³ãƒ—ãƒ«ãªæŒ‡æ¨™**ã§å‰²å®‰æ ªã‚’è¦‹ã¤ã‘ã‚‹æ‰‹æ³•ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã¾ã™ï¼š

- **æ™‚ä¾¡ç·é¡**: 500 å„„ä»¥ä¸‹
- **PBR**: 1 å€ä»¥ä¸‹
- **PER**: 10 å€ä»¥ä¸‹
- **ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥**: ï¼ˆæµå‹•è³‡ç”£ï¼‹æŠ•è³‡æœ‰ä¾¡è¨¼åˆ¸ Ã—70ï¼…ï¼‰ï¼è² å‚µ
- **ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡**ã€€ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥/æ™‚ä¾¡ç·é¡

ã“ã‚Œã‚‰ã®æŒ‡æ¨™ã‚’**è‡ªå‹•ã§å–å¾—ãƒ»åˆ†æ**ã§ãã‚Œã°ã€ã²ã¨ã¾ãšã€Œã‚ãŒæŠ•è³‡è¡“ã€ã«ç²—æ–¹æ²¿ã£ãŸã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãŒã§ãã‚‹ã¨æ€ã„ã¾ã™ã€‚
ãªã®ã§ã€ã“ã‚Œã‚‰ã®åŸºæœ¬çš„ãªã‚‚ã®ã«åŠ ãˆã¦ã€ä»¥ä¸‹ã®ã‚‚ã®ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡ºæ¥ã‚‹ã‚ˆã†ã«ã—ã¦ã„ãã¾ã™ã€‚

### å®Ÿè£…æ¸ˆã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é …ç›®

#### ğŸ“‹ åŸºæœ¬ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼

![search1](https://raw.githubusercontent.com/testkun08080/zenn-docs/main/images/python-yfinance-4c4331412bc50f/img_search1.png)

- **ä¼šç¤¾åæ¤œç´¢** - ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰
- **éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰æ¤œç´¢** - ã‚³ãƒ¼ãƒ‰æ¤œç´¢
- **æ™‚ä¾¡ç·é¡** -
- **æ¥­ç¨®** - è¤‡æ•°é¸æŠå¯èƒ½ï¼ˆãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ï¼‰
- **å„ªå…ˆå¸‚å ´** - ãƒ—ãƒ©ã‚¤ãƒ /ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰/ã‚°ãƒ­ãƒ¼ã‚¹ï¼ˆè¤‡æ•°é¸æŠï¼‰
- **éƒ½é“åºœçœŒ** - æœ¬ç¤¾æ‰€åœ¨åœ°ã«ã‚ˆã‚‹çµã‚Šè¾¼ã¿ï¼ˆè¤‡æ•°é¸æŠï¼‰

#### ğŸ“Š ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³æŒ‡æ¨™

![search2](https://raw.githubusercontent.com/testkun08080/zenn-docs/main/images/python-yfinance-4c4331412bc50f/img_search2.png)

- **PBRï¼ˆæ ªä¾¡ç´”è³‡ç”£å€ç‡ï¼‰**
- **ROEï¼ˆè‡ªå·±è³‡æœ¬åˆ©ç›Šç‡ï¼‰**
- **è‡ªå·±è³‡æœ¬æ¯”ç‡**
- **PER(ä¼šäºˆ)ï¼ˆäºˆæƒ³æ ªä¾¡åç›Šç‡ï¼‰**

#### ğŸ’¹ æ¥­ç¸¾ãƒ»åç›Šæ€§æŒ‡æ¨™

![search3](https://raw.githubusercontent.com/testkun08080/zenn-docs/main/images/python-yfinance-4c4331412bc50f/img_search3.png)

- **å£²ä¸Šé«˜**
- **å–¶æ¥­åˆ©ç›Š**
- **å–¶æ¥­åˆ©ç›Šç‡**
- **å½“æœŸç´”åˆ©ç›Š**
- **ç´”åˆ©ç›Šç‡**

#### ğŸ›ï¸ ãƒãƒ©ãƒ³ã‚¹ã‚·ãƒ¼ãƒˆæŒ‡æ¨™

![search4](https://raw.githubusercontent.com/testkun08080/zenn-docs/main/images/python-yfinance-4c4331412bc50f/img_search4.png)

- **è² å‚µ**
- **æµå‹•è² å‚µ**
- **æµå‹•è³‡ç”£**
- **ç·è² å‚µ**
- **æŠ•è³‡æœ‰ä¾¡è¨¼åˆ¸**

#### ğŸ’° ã‚­ãƒ£ãƒƒã‚·ãƒ¥é–¢é€£æŒ‡æ¨™

![search5](https://raw.githubusercontent.com/testkun08080/zenn-docs/main/images/python-yfinance-4c4331412bc50f/img_search5.png)

- **ç¾é‡‘åŠã³ç¾é‡‘åŒç­‰ç‰©**
- **ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥**
- **ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡**

# æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ (JPXå…¬å¼ + Yahoo Finance)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                               â”‚
         â†“                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GitHub Actions    â”‚        â”‚ ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ          â”‚
â”‚  (CI/CDè‡ªå‹•åé›†)    â”‚        â”‚ (Docker Compose).   â”‚
â”‚                    â”‚        â”‚                     â”‚
â”‚  Part 1-4          â”‚        â”‚  Python Service     â”‚
â”‚  â†’ CSV Combine     â”‚        â”‚  â†’ CSVç”Ÿæˆ           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                               â”‚
         â†“                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            CSV ãƒ•ã‚¡ã‚¤ãƒ« (Export/)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         React ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ (Docker/Local)      ã€€â”‚
â”‚  CSV Drag & Drop â†’ æ¤œç´¢ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ â†’ çµæœè¡¨ç¤º        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

<details><summary>è©³ç´°</summary>


```mermaid
graph TB
    subgraph "ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹"
        JPX[JPXå…¬å¼ãƒ‡ãƒ¼ã‚¿<br/>ç´„3,795éŠ˜æŸ„]
        Yahoo[Yahoo Finance API<br/>yfinance]
    end

    subgraph "æ–¹æ³•1: GitHub Actions - è‡ªå‹•åé›†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"
        StockList[Stock List Update<br/>æ ªå¼ãƒªã‚¹ãƒˆå–å¾—]
        Part1[Sequential Part 1<br/>stocks_1.json<br/>1-1000ç¤¾]
        Part2[Sequential Part 2<br/>stocks_2.json<br/>1001-2000ç¤¾]
        Part3[Sequential Part 3<br/>stocks_3.json<br/>2001-3000ç¤¾]
        Part4[Sequential Part 4<br/>stocks_4.json<br/>3001-3795ç¤¾]
        Combine[CSV Combine<br/>ãƒ‡ãƒ¼ã‚¿çµåˆ]
        CSV_GA[CSVå‡ºåŠ›<br/>Export/]
    end

    subgraph "æ–¹æ³•2: ãƒ­ãƒ¼ã‚«ãƒ« Docker Compose"
        subgraph "Python Service"
            DataProcess[ãƒ‡ãƒ¼ã‚¿å‡¦ç†<br/>sumalize.py]
            CSV_Local[CSVç”Ÿæˆ<br/>Export/]
        end
    end

    subgraph "ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ¸ˆã¿CSV"
        CSVFiles[(CSV ãƒ•ã‚¡ã‚¤ãƒ«<br/>Export/<br/>YYYYMMDD_combined.csv)]
    end

    subgraph "å®Œæˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ (Docker/Local)"
        subgraph "React Webã‚¢ãƒ—ãƒª"
            React[React 19 + TypeScript<br/>Vite]
            Nginx[nginx<br/>é™çš„é…ä¿¡]
        end

        subgraph "ãƒ–ãƒ©ã‚¦ã‚¶ UI"
            UI[Webã‚¢ãƒ—ãƒªèµ·å‹•<br/>localhost:8080(PORTè¨­å®šä¾å­˜)]
            Upload[CSV DnD<br/>ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½]
            Table[ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«<br/>æ¤œç´¢ãƒ»ãƒ•ã‚£ãƒ«ã‚¿]
            Analysis[è²¡å‹™åˆ†æ<br/>PBR/ROE/è‡ªå·±è³‡æœ¬æ¯”ç‡]
        end
    end

    %% GitHub Actions ãƒ•ãƒ­ãƒ¼
    JPX -->|Excelâ†’JSONå¤‰æ›| StockList
    StockList -->|è‡ªå‹•ãƒˆãƒªã‚¬ãƒ¼| Part1
    Part1 -->|è‡ªå‹•ãƒˆãƒªã‚¬ãƒ¼| Part2
    Part2 -->|è‡ªå‹•ãƒˆãƒªã‚¬ãƒ¼| Part3
    Part3 -->|è‡ªå‹•ãƒˆãƒªã‚¬ãƒ¼| Part4
    Part4 -->|è‡ªå‹•ãƒˆãƒªã‚¬ãƒ¼| Combine

    Yahoo -->|APIå–å¾—| Part1
    Yahoo -->|APIå–å¾—| Part2
    Yahoo -->|APIå–å¾—| Part3
    Yahoo -->|APIå–å¾—| Part4

    Combine -->|CSVå‡ºåŠ›| CSV_GA
    CSV_GA -->|ä¿å­˜| CSVFiles

    %% ãƒ­ãƒ¼ã‚«ãƒ« Docker ãƒ•ãƒ­ãƒ¼
    JPX -->|JSONå–å¾—| DataProcess
    Yahoo -->|APIå–å¾—| DataProcess
    DataProcess -->|CSVç”Ÿæˆ| CSV_Local
    CSV_Local -->|ä¿å­˜| CSVFiles

    %% ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•ãƒ•ãƒ­ãƒ¼
    React -->|ãƒ“ãƒ«ãƒ‰| Nginx
    Nginx -->|HTTPé…ä¿¡| UI

    %% ãƒ¦ãƒ¼ã‚¶ãƒ¼æ“ä½œãƒ•ãƒ­ãƒ¼ (CSV â†’ ã‚¢ãƒ—ãƒª)
    CSVFiles -.->|ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ‰‹å‹•ã§<br/>Drag & Drop| Upload
    Upload -->|CSVãƒ‘ãƒ¼ã‚¹| Table
    Table --> Analysis

    style JPX fill:#e1f5ff
    style Yahoo fill:#e1f5ff
    style StockList fill:#fff4e6
    style Part1 fill:#f3e5f5
    style Part2 fill:#f3e5f5
    style Part3 fill:#f3e5f5
    style Part4 fill:#f3e5f5
    style Combine fill:#fff4e6
    style CSV_GA fill:#e8f5e9
    style DataProcess fill:#e8f5e9
    style CSV_Local fill:#e8f5e9
    style CSVFiles fill:#fce4ec
    style Upload fill:#ffe0b2
    style React fill:#e3f2fd
    style Nginx fill:#e3f2fd
    style UI fill:#f1f8e9
    style Table fill:#fff9c4
    style Analysis fill:#fff9c4
```

</details>

## ãƒ‡ãƒ¼ã‚¿åé›†ï¼ˆPythonï¼‰

- **Python 3.11+**
- **yfinance**

## ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ï¼ˆReactï¼‰

- **React 19**
- **TypeScript**
- **Vite**
- **Tailwind CSS + DaisyUI**

## ã‚¤ãƒ³ãƒ•ãƒ©

- **GitHub Actions**
- **Docker Compose**

# é–‹ç™ºã®ãƒã‚¤ãƒ³ãƒˆ

## 1. ãƒ‡ãƒ¼ã‚¿åé›†ã®è‡ªå‹•åŒ–

### èª²é¡Œ: yfinance API ã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™

ç´„ 3,795 ç¤¾ã®ãƒ‡ãƒ¼ã‚¿ã‚’ Github Actions ã§ä¸€åº¦ã«å–å¾—ã™ã‚‹ã¨ã€API ã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚„ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒç™ºç”Ÿã—ã¾ã™ã€‚
ï¼ˆç®¡ç†ä¸Šã‚‚åˆ†ã‘ãŸã‹ã£ãŸã¨ã„ã†æ„å›³ã‚‚ã‚ã‚Šã¾ã™ã€‚ï¼‰

### åˆ†å‰²å‡¦ç†

GitHub Actions ã§**4 æ®µéšã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼**ã‚’æ§‹ç¯‰ã—ã€è‡ªå‹•é€£æºã•ã›ã¾ã—ãŸã€‚

```yaml
# Part 1 â†’ Part 2 â†’ Part 3 â†’ Part 4 â†’ CSVçµåˆ
Sequential Stock Fetch - Part 1 (stocks_1.json: 1,000ç¤¾)
  â†“ è‡ªå‹•ãƒˆãƒªã‚¬ãƒ¼
Sequential Stock Fetch - Part 2 (stocks_2.json: 1,000ç¤¾)
  â†“ è‡ªå‹•ãƒˆãƒªã‚¬ãƒ¼
Sequential Stock Fetch - Part 3 (stocks_3.json: 1,000ç¤¾)
  â†“ è‡ªå‹•ãƒˆãƒªã‚¬ãƒ¼
Sequential Stock Fetch - Part 4 (stocks_4.json: 795ç¤¾)
  â†“ è‡ªå‹•ãƒˆãƒªã‚¬ãƒ¼
CSV Combine & Export (å…¨ãƒ‡ãƒ¼ã‚¿çµåˆ)
```

### å®Ÿè£…ã‚³ãƒ¼ãƒ‰ï¼ˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é€£æºéƒ¨åˆ†ï¼‰

```yaml
name: ğŸ“Š Sequential Stock Fetch - Part 1

permissions:
  contents: write
  actions: write

on:
  workflow_dispatch:
    inputs:
      reason:
        description: "é–‹å§‹ç†ç”±ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰"
        required: false
        default: "Sequential stock data collection - Part 1"
        type: string

jobs:
  fetch-stocks-1:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    permissions:
      contents: write

    outputs:
      success: ${{ steps.process.outcome == 'success' }}

    steps:
      - name: ğŸ”„ Checkout repository
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"
          cache: "pip"

      - name: ğŸ“¦ Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r stock_list/requirements.txt

      - name: ğŸ“‹ Show process info
        run: |
          echo "ğŸš€ Sequential Stock Fetch - Part 1/4"
          echo "Processing file: stocks_1.json"
          echo "Reason: ${{ github.event.inputs.reason }}"
          echo "Timestamp: $(date)"
          echo "Working directory: $(pwd)"
          ls -la stock_list/

      - name: ğŸƒ Process stocks_1.json
        id: process
        working-directory: ./stock_list
        run: |
          echo "ğŸš€ Starting stock data collection for stocks_1.json..."
          echo "Timestamp: $(date)"

          python sumalize.py "stocks_1.json"

          echo "âœ… Part 1 completed successfully"
          echo "ğŸ“„ Generated files in Export directory:"
          ls -la Export/ 2>/dev/null || echo "No files in Export directory"

      - name: Git config and pull
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git pull origin main --rebase || true

      - name: ğŸ’¾ Commit changes - Part 1
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "ğŸ“Š Sequential Stock Fetch - Part 1/4 å®Œäº† ($(date +'%Yå¹´%mæœˆ%dæ—¥ %H:%M'))"
          push_options: --force

  trigger-part-2:
    needs: fetch-stocks-1
    runs-on: ubuntu-latest
    if: needs.fetch-stocks-1.outputs.success == 'true'

    steps:
      - name: ğŸ”„ Checkout repository
        uses: actions/checkout@v4

      - name: ğŸš€ Trigger Part 2
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const result = await github.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'stock-fetch-sequential-2.yml',
              ref: 'main',
              inputs: {
                reason: 'Auto-triggered by Part 1 completion'
              }
            });

            console.log('âœ… Part 2 triggered successfully');
            console.log('Response status:', result.status);
```

## 2. ãƒ‡ãƒ¼ã‚¿åé›†ã«ã¤ã„ã¦

### JPX å…¬å¼ãƒ‡ãƒ¼ã‚¿ã®å–å¾—

JPXï¼ˆæ—¥æœ¬å–å¼•æ‰€ã‚°ãƒ«ãƒ¼ãƒ—ï¼‰ã®å…¬å¼ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã‹ã‚‰ã€
ä¸Šå ´ä¼æ¥­ã®æœ€æ–°æ ªå¼ãƒªã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€JSON å½¢å¼ã§ä¿å­˜ã—ã¾ã™ã€‚

```python
import requests
import pandas as pd
import xlrd
from openpyxl import Workbook
import json
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()],
)
logger = logging.getLogger(__name__)

# ãƒ•ã‚¡ã‚¤ãƒ«ã®URL
url = "https://www.jpx.co.jp/markets/statistics-equities/misc/tvdivq0000001vg2-att/data_j.xls"

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
response = requests.get(url)

# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
xls_file = "tickers.xls"
with open(xls_file, "wb") as f:
    f.write(response.content)

# .xlsãƒ•ã‚¡ã‚¤ãƒ«ã‚’ .xlsx ã«å¤‰æ›
xlsx_file = "converted.xlsx"
workbook_xls = xlrd.open_workbook(xls_file)
sheet_xls = workbook_xls.sheet_by_index(0)

workbook_xlsx = Workbook()
sheet_xlsx = workbook_xlsx.active

# ãƒ‡ãƒ¼ã‚¿ã‚’ .xls ã‹ã‚‰ .xlsx ã«æ›¸ãè¾¼ã‚€
for row in range(sheet_xls.nrows):
    for col in range(sheet_xls.ncols):
        sheet_xlsx.cell(row=row + 1, column=col + 1).value = sheet_xls.cell_value(row, col)

# .xlsx ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
workbook_xlsx.save(xlsx_file)

# å¤‰æ›ã•ã‚ŒãŸ .xlsx ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
data = pd.read_excel(xlsx_file)

# ORæ¡ä»¶ã‚’ä½¿ç”¨ã—ã¦æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹è¡Œã‚’æŠ½å‡º
condition = (
    (data["å¸‚å ´ãƒ»å•†å“åŒºåˆ†"] == "ãƒ—ãƒ©ã‚¤ãƒ ï¼ˆå†…å›½æ ªå¼ï¼‰")
    | (data["å¸‚å ´ãƒ»å•†å“åŒºåˆ†"] == "ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ï¼ˆå†…å›½æ ªå¼ï¼‰")
    | (data["å¸‚å ´ãƒ»å•†å“åŒºåˆ†"] == "ã‚°ãƒ­ãƒ¼ã‚¹ï¼ˆå†…å›½æ ªå¼ï¼‰")
)

filtered_df = data[condition]

# å¿…è¦ãªåˆ—ã ã‘ã‚’æŠ½å‡º
selected_df = filtered_df[["ã‚³ãƒ¼ãƒ‰", "éŠ˜æŸ„å", "å¸‚å ´ãƒ»å•†å“åŒºåˆ†", "33æ¥­ç¨®åŒºåˆ†"]]

# DataFrame ã‚’ JSON å½¢å¼ï¼ˆãƒªã‚¹ãƒˆã®è¾æ›¸å½¢å¼ï¼‰ã«å¤‰æ›
json_list = selected_df.to_dict(orient="records")

# JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
with open("stocks_all.json", "w", encoding="utf-8") as f:
    json.dump(json_list, f, ensure_ascii=False, indent=2)

logger.info("JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã—ãŸ: stocks_all.json")

```

### ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚·ãƒ³ãƒœãƒ«ã‚’ json ã¸ä¿å­˜ã—ç›´ã™ï¼ˆåˆ†å‰²ã—ãŸã„ãŸã‚ï¼‰

stocks_all.json ã‚’ XXXX ç¤¾ãšã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«åˆ†å‰²ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```python
import json
import math
import argparse
import sys
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()],
)
logger = logging.getLogger(__name__)


def split_stocks_json(input_file="stocks_all.json", chunk_size=1000):
    """
    stocks_all.jsonã‚’æŒ‡å®šã•ã‚ŒãŸã‚µã‚¤ã‚ºã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²

    Args:
        input_file (str): å…¥åŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«å
        chunk_size (int): 1ãƒ•ã‚¡ã‚¤ãƒ«ã‚ãŸã‚Šã®ä¼æ¥­æ•°
    """
    try:
        # å…ƒã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        with open(input_file, "r", encoding="utf-8") as f:
            stock_data = json.load(f)

        total_companies = len(stock_data)
        total_files = math.ceil(total_companies / chunk_size)

        logger.info(f"ç·ä¼æ¥­æ•°: {total_companies}ç¤¾")
        logger.info(f"åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_files}ãƒ•ã‚¡ã‚¤ãƒ«")
        logger.info(f"1ãƒ•ã‚¡ã‚¤ãƒ«ã‚ãŸã‚Š: æœ€å¤§{chunk_size}ç¤¾")
        logger.info("-" * 50)

        # ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¦ä¿å­˜
        for i in range(total_files):
            start_idx = i * chunk_size
            end_idx = min((i + 1) * chunk_size, total_companies)
            chunk_data = stock_data[start_idx:end_idx]

            # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆï¼ˆstocks_1.json, stocks_2.json, ...ï¼‰
            output_filename = f"stocks_{i + 1}.json"

            # JSONå½¢å¼ã§ä¿å­˜
            with open(output_filename, "w", encoding="utf-8") as f:
                json.dump(chunk_data, f, ensure_ascii=False, indent=2)

            logger.info(
                f"âœ… {output_filename}: {len(chunk_data)}ç¤¾ (#{start_idx + 1}-#{end_idx})"
            )

        logger.info("-" * 50)
        logger.info(f"åˆ†å‰²å®Œäº†: {total_files}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ")

        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±ã‚’è¡¨ç¤º
        logger.info("\nä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
        for i in range(total_files):
            filename = f"stocks_{i + 1}.json"
            with open(filename, "r", encoding="utf-8") as f:
                data = json.load(f)
            logger.info(f"  {filename}: {len(data)}ç¤¾")

    except FileNotFoundError:
        logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {input_file}ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    except json.JSONDecodeError:
        logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {input_file}ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")
    except Exception as e:
        logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="æ—¥æœ¬æ ªãƒªã‚¹ãƒˆJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã•ã‚ŒãŸã‚µã‚¤ã‚ºã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¾ã™",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  python split_stocks.py                           # stocks_all.jsonã‚’1000ç¤¾ãšã¤ã«åˆ†å‰²
  python split_stocks.py -i stocks_all.json       # stocks_all.jsonã‚’1000ç¤¾ãšã¤ã«åˆ†å‰²
  python split_stocks.py -i data.json -s 500      # data.jsonã‚’500ç¤¾ãšã¤ã«åˆ†å‰²
  python split_stocks.py --input stocks_all.json --size 2000  # 2000ç¤¾ãšã¤ã«åˆ†å‰²
        """,
    )

    parser.add_argument(
        "-i",
        "--input",
        default="stocks_all.json",
        help="å…¥åŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«å (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: stocks_all.json)",
    )

    parser.add_argument(
        "-s",
        "--size",
        type=int,
        default=1000,
        help="1ãƒ•ã‚¡ã‚¤ãƒ«ã‚ãŸã‚Šã®ä¼æ¥­æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1000)",
    )

    parser.add_argument("-v", "--verbose", action="store_true", help="è©³ç´°ãªå‡ºåŠ›ã‚’è¡¨ç¤º")

    args = parser.parse_args()

    # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    if args.size <= 0:
        logger.error("âŒ ã‚¨ãƒ©ãƒ¼: ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã¯æ­£ã®æ•´æ•°ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
        sys.exit(1)

    logger.info("=" * 60)
    logger.info("ğŸ“Š stocks_all.jsonåˆ†å‰²ãƒ„ãƒ¼ãƒ«")
    logger.info("=" * 60)
    logger.info(f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {args.input}")
    logger.info(f"ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {args.size}ç¤¾")
    if args.verbose:
        logger.info("è©³ç´°ãƒ¢ãƒ¼ãƒ‰: ON")
    logger.info("=" * 60)

    split_stocks_json(input_file=args.input, chunk_size=args.size)

```

#### yfinance ã§ã®è²¡å‹™ãƒ‡ãƒ¼ã‚¿å–å¾—

ãƒ¡ã‚¤ãƒ³å‡¦ç†ã¯ã€ã‚·ãƒ³ãƒ—ãƒ«ã«èª­ã¿è¾¼ã‚“ã  json é‡ä¸­ã‹ã‚‰ãƒ†ã‚£ãƒƒã‚«ãƒ¼çµã‚‹ã”ã¨ã«å›ã‚‹ã ã‘ã§ã™ã€‚

```python
def main(json_filename="stocks_sample.json"):
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†

    Args:
        json_filename (str): å‡¦ç†å¯¾è±¡ã®JSONãƒ•ã‚¡ã‚¤ãƒ«å
    """
    overall_start_time = time.time()
    overall_start_datetime = datetime.now()

    logger.info("=" * 80)
    logger.info(f"æ—¥æœ¬æ ªè²¡å‹™ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹ - é–‹å§‹æ™‚åˆ»: {overall_start_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {json_filename}")
    logger.info("=" * 80)

    # æŒ‡å®šã•ã‚ŒãŸJSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    try:
        with open(json_filename, "r", encoding="utf-8") as f:
            stock_list = json.load(f)
        logger.info(f"{json_filename}ã‹ã‚‰{len(stock_list)}ç¤¾ã®éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    except FileNotFoundError:
        logger.error(f"âŒ {json_filename}ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return None
    except json.JSONDecodeError:
        logger.error(f"âŒ {json_filename}ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")
        return None

    logger.info("=" * 60)
    logger.info("æ—¥æœ¬æ ªè²¡å‹™ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹")
    logger.info("=" * 60)

    results = []

    for i, stock in enumerate(stock_list, 1):
        logger.info(f"\n[{i}/{len(stock_list)}]")
        result = get_stock_data(stock)

        if result:
            results.append(result)

        # APIåˆ¶é™å›é¿ã®ãŸã‚å°‘ã—å¾…æ©Ÿ
        if i < len(stock_list):
            time.sleep(2)

    # çµæœã‚’DataFrameã«å¤‰æ›
    if results:
        df = pd.DataFrame(results)

        # åˆ—ã®é †åºã‚’æŒ‡å®š
        columns_order = [
            "ä¼šç¤¾å",
            "éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰",
            "æ¥­ç¨®",
            "å„ªå…ˆå¸‚å ´",
            "æ±ºç®—æœˆ",
            "éƒ½é“åºœçœŒ",
            "æ™‚ä¾¡ç·é¡",
            "PBR",
            "å£²ä¸Šé«˜",
            "å–¶æ¥­åˆ©ç›Š",
            "å–¶æ¥­åˆ©ç›Šç‡",
            "å½“æœŸç´”åˆ©ç›Š",
            "ç´”åˆ©ç›Šç‡",
            "ROE",
            "è‡ªå·±è³‡æœ¬æ¯”ç‡",
            "PER(ä¼šäºˆ)",
            "è² å‚µ",
            "æµå‹•è² å‚µ",
            "æµå‹•è³‡ç”£",
            "ç·è² å‚µ",
            "ç¾é‡‘åŠã³ç¾é‡‘åŒç­‰ç‰©",
            "æŠ•è³‡æœ‰ä¾¡è¨¼åˆ¸",
            "ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥",
            "ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡",
        ]

        df = df.reindex(columns=columns_order)

        overall_end_time = time.time()
        overall_end_datetime = datetime.now()
        overall_duration = overall_end_time - overall_start_time

        # çµæœã‚’è¡¨ç¤º
        logger.info("\n" + "=" * 60)
        logger.info("å–å¾—çµæœã‚µãƒãƒªãƒ¼")
        logger.info("=" * 60)
        logger.info(f"å–å¾—æˆåŠŸ: {len(results)}ç¤¾")
        logger.info(f"å–å¾—å¤±æ•—: {len(stock_list) - len(results)}ç¤¾")

        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆExport ãƒ•ã‚©ãƒ«ãƒ€ã«ç›´æ¥ä¿å­˜ï¼‰
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        base_name = json_filename.replace(".json", "").replace("stocks_", "")

        filename = f"Export/japanese_stocks_data_{base_name}_{timestamp}.csv"
        df.to_csv(filename, index=False, encoding="utf-8-sig")
        logger.info(f"\nãƒ‡ãƒ¼ã‚¿ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã—ãŸ: {filename}")

        # ãƒ‡ãƒ¼ã‚¿ã®ä¸€éƒ¨ã‚’è¡¨ç¤º
        logger.info("\nå–å¾—ãƒ‡ãƒ¼ã‚¿ï¼ˆæœ€åˆã®3åˆ—ï¼‰:")
        logger.info(f"\n{df[['ä¼šç¤¾å', 'éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰', 'æ™‚ä¾¡ç·é¡', 'PBR', 'ROE']].head()}")

        # å…¨ä½“ã®å®Ÿè¡Œæ™‚é–“ã‚’ãƒ­ã‚°å‡ºåŠ›
        logger.info("=" * 80)
        logger.info("æ—¥æœ¬æ ªè²¡å‹™ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ—ãƒ­ã‚»ã‚¹å®Œäº†")
        logger.info(f"é–‹å§‹æ™‚åˆ»: {overall_start_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"çµ‚äº†æ™‚åˆ»: {overall_end_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"ç·å®Ÿè¡Œæ™‚é–“: {format_duration(overall_duration)}")
        logger.info(
            f"å‡¦ç†çµæœ: æˆåŠŸ {len(results)}ç¤¾ / å¤±æ•— {len(stock_list) - len(results)}ç¤¾ / åˆè¨ˆ {len(stock_list)}ç¤¾"
        )
        logger.info(f"å¹³å‡å‡¦ç†æ™‚é–“: {format_duration(overall_duration / len(stock_list))}ï¼ˆ1ç¤¾ã‚ãŸã‚Šï¼‰")
        logger.info(f"ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«: {filename}")
        logger.info("=" * 80)

        return df
    else:
        overall_end_time = time.time()
        overall_end_datetime = datetime.now()
        overall_duration = overall_end_time - overall_start_time

        logger.error("\nâŒ ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        logger.error("=" * 80)
        logger.error("æ—¥æœ¬æ ªè²¡å‹™ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ—ãƒ­ã‚»ã‚¹å¤±æ•—")
        logger.error(f"é–‹å§‹æ™‚åˆ»: {overall_start_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.error(f"çµ‚äº†æ™‚åˆ»: {overall_end_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.error(f"ç·å®Ÿè¡Œæ™‚é–“: {format_duration(overall_duration)}")
        logger.error("ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        logger.error("=" * 80)
        return None


```

å€‹åˆ¥éŠ˜æŸ„ã®è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ã„ãã¾ã™ã€‚
ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚·ãƒ³ãƒœãƒ«ã”ã¨ã«ã»ã—ã„æƒ…å ±ã‚’æ—¥æœ¬èªã«ç›´ã—ãªãŒã‚‰ã€ãƒ‡ãƒ¼ã‚¿ã‚’ä½œã£ã¦è¿”ã—ã¾ã™ã€‚

```python
def get_stock_data(stock_info):
    code = stock_info["ã‚³ãƒ¼ãƒ‰"]
    ticker_symbol = format_ticker(code)

    start_time = time.time()
    start_datetime = datetime.now()

    logger.info(f"å–å¾—ä¸­: {stock_info['éŠ˜æŸ„å']} ({ticker_symbol})")
    logger.debug(
        f"ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹: {stock_info['éŠ˜æŸ„å']} ({ticker_symbol}) - é–‹å§‹æ™‚åˆ»: {start_datetime.strftime('%Y-%m-%d %H:%M:%S')}"
    )

    try:
        # yfinanceã§ãƒ†ã‚£ãƒƒã‚«ãƒ¼ä½œæˆ
        ticker = yf.Ticker(ticker_symbol)

        # åŸºæœ¬æƒ…å ±å–å¾—
        info = ticker.info
        if not info:
            logger.warning(f"  âš ï¸ åŸºæœ¬æƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {ticker_symbol}")
            return None

        # æ™‚é–“ã‚’ç½®ã„ã¦APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’å›é¿
        time.sleep(0.5)

        # è²¡å‹™è«¸è¡¨ãƒ‡ãƒ¼ã‚¿å–å¾—
        try:
            financials = ticker.financials
            balance_sheet = ticker.balance_sheet
        except Exception as e:
            logger.warning(f"  âš ï¸ è²¡å‹™è«¸è¡¨å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            financials = pd.DataFrame()
            balance_sheet = pd.DataFrame()

        # æ±ºç®—æœˆã‚’å–å¾—ï¼ˆãƒãƒ©ãƒ³ã‚¹ã‚·ãƒ¼ãƒˆã®æœ€æ–°æœŸã‹ã‚‰ï¼‰
        settlement_period = None
        if not balance_sheet.empty:
            cols = balance_sheet.columns.tolist()
            if cols:
                # æœ€æ–°æ±ºç®—æœŸã‹ã‚‰æ—¥ä»˜éƒ¨åˆ†ã®ã¿æŠ½å‡ºï¼ˆä¾‹ï¼š2025-03-31ï¼‰
                latest_period = cols[0]
                if hasattr(latest_period, "strftime"):
                    # datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆã€æ—¥ä»˜éƒ¨åˆ†ã®ã¿å–å¾—
                    settlement_period = latest_period.strftime("%Y-%m-%d")
                else:
                    # æ–‡å­—åˆ—ã®å ´åˆã€æ™‚é–“éƒ¨åˆ†ã‚’å‰Šé™¤
                    settlement_period = str(latest_period).split(" ")[0]

        # PER(ä¼šäºˆ)ã®ãƒ‡ãƒãƒƒã‚°
        forward_pe = info.get("forwardPE", None)

        # ãƒ‡ãƒ¼ã‚¿åé›†
        result = {
            "ä¼šç¤¾å": stock_info["éŠ˜æŸ„å"] or safe_get_value(info, "longName") or safe_get_value(info, "shortName"),
            "éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰": code,
            "æ¥­ç¨®": stock_info.get("33æ¥­ç¨®åŒºåˆ†") or safe_get_value(info, "industry") or safe_get_value(info, "sector"),
            "å„ªå…ˆå¸‚å ´": stock_info.get("å¸‚å ´ãƒ»å•†å“åŒºåˆ†", ""),
            "æ±ºç®—æœˆ": settlement_period,
            # "ä¼šè¨ˆåŸºæº–": None,  # yfinanceã§ã¯è©³ç´°ä¸æ˜ - ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
            "éƒ½é“åºœçœŒ": get_prefecture_from_zip(safe_get_value(info, "zip")) or None,
            "æ™‚ä¾¡ç·é¡": safe_get_value(info, "marketCap"),
            "PBR": safe_get_value(info, "priceToBook"),
            "PER(ä¼šäºˆ)": forward_pe,
            "ROE": safe_get_value(info, "returnOnEquity"),
            "å–¶æ¥­åˆ©ç›Šç‡": safe_get_value(info, "operatingMargins"),
            "ç´”åˆ©ç›Šç‡": safe_get_value(info, "profitMargins"),
        }

        # è²¡å‹™è«¸è¡¨ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
        if not financials.empty:
            result["å£²ä¸Šé«˜"] = safe_get_financial_data(ticker, "financials", "Total Revenue")
            result["å–¶æ¥­åˆ©ç›Š"] = safe_get_financial_data(ticker, "financials", "Operating Income")
            result["å½“æœŸç´”åˆ©ç›Š"] = safe_get_financial_data(ticker, "financials", "Net Income")
        else:
            result.update({"å£²ä¸Šé«˜": None, "å–¶æ¥­åˆ©ç›Š": None, "å½“æœŸç´”åˆ©ç›Š": None})

        if not balance_sheet.empty:
            # ãƒãƒ©ãƒ³ã‚¹ã‚·ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆtest.csvã®é …ç›®åã«åŸºã¥ãã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰
            total_liabilities = safe_get_financial_data(
                ticker,
                "balance_sheet",
                "Total Liabilities Net Minority Interest",
                fallback_items=["Total Liab"],
            )
            current_liabilities = safe_get_financial_data(
                ticker,
                "balance_sheet",
                "Current Liabilities",
                fallback_items=["Total Current Liabilities"],
            )
            current_assets = safe_get_financial_data(
                ticker,
                "balance_sheet",
                "Current Assets",
                fallback_items=["Total Current Assets"],
            )
            total_equity = safe_get_financial_data(
                ticker,
                "balance_sheet",
                "Stockholders Equity",
                fallback_items=["Total Stockholder Equity"],
            )
            total_assets = safe_get_financial_data(ticker, "balance_sheet", "Total Assets")
            total_debt = safe_get_financial_data(ticker, "balance_sheet", "Total Debt")
            cash_and_equivalents = safe_get_financial_data(
                ticker,
                "balance_sheet",
                "Cash And Cash Equivalents",
                fallback_items=["Cash Cash Equivalents And Short Term Investments"],
            )
            investments = safe_get_financial_data(
                ticker,
                "balance_sheet",
                "Available For Sale Securities",
                fallback_items=[
                    "Short Term Investments",
                    "Investmentin Financial Assets",
                ],
            )

            result.update({
                "è² å‚µ": total_liabilities,
                "æµå‹•è² å‚µ": current_liabilities,
                "æµå‹•è³‡ç”£": current_assets,
                "ç·è² å‚µ": total_debt,
                "ç¾é‡‘åŠã³ç¾é‡‘åŒç­‰ç‰©": cash_and_equivalents,
                "æŠ•è³‡æœ‰ä¾¡è¨¼åˆ¸": investments,
            })

            # è‡ªå·±è³‡æœ¬æ¯”ç‡ã®è¨ˆç®—
            if total_equity and total_assets:
                result["è‡ªå·±è³‡æœ¬æ¯”ç‡"] = total_equity / total_assets
            else:
                result["è‡ªå·±è³‡æœ¬æ¯”ç‡"] = None

            # ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®è¨ˆç®—ï¼ˆæµå‹•è³‡ç”£ + æŠ•è³‡æœ‰ä¾¡è¨¼åˆ¸Ã—70% - è² å‚µï¼‰
            net_cash = calculate_net_cash(current_assets, investments, total_liabilities)
            result["ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥"] = net_cash

            # ãƒ‡ãƒãƒƒã‚°ç”¨: ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨ˆç®—ã®è©³ç´°ã‚’è¡¨ç¤º
            if any(x is not None for x in [current_assets, investments, total_liabilities]):
                inv_70 = (investments * 0.7) if investments is not None else 0
                logger.debug(
                    f"  ğŸ“Š ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨ˆç®—: {current_assets} + {inv_70:.0f} - {total_liabilities} = {net_cash}"
                )

            # ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡ã®è¨ˆç®—
            if net_cash and result["æ™‚ä¾¡ç·é¡"]:
                result["ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡"] = net_cash / result["æ™‚ä¾¡ç·é¡"]
            else:
                result["ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡"] = None
        else:
            result.update({
                "è² å‚µ": None,
                "æµå‹•è² å‚µ": None,
                "æµå‹•è³‡ç”£": None,
                "ç·è² å‚µ": None,
                "ç¾é‡‘åŠã³ç¾é‡‘åŒç­‰ç‰©": None,
                "æŠ•è³‡æœ‰ä¾¡è¨¼åˆ¸": None,
                "è‡ªå·±è³‡æœ¬æ¯”ç‡": None,
                "ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥": None,
                "ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡": None,
            })

        end_time = time.time()
        end_datetime = datetime.now()
        duration = end_time - start_time

        logger.info(f"  âœ… å–å¾—å®Œäº†: {result['ä¼šç¤¾å']}")
        logger.debug(
            f"ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {result['ä¼šç¤¾å']} ({ticker_symbol}) - çµ‚äº†æ™‚åˆ»: {end_datetime.strftime('%Y-%m-%d %H:%M:%S')} - å®Ÿè¡Œæ™‚é–“: {format_duration(duration)}"
        )
        return result

    except Exception as e:
        end_time = time.time()
        end_datetime = datetime.now()
        duration = end_time - start_time

        logger.error(f"  âŒ ã‚¨ãƒ©ãƒ¼: {ticker_symbol} - {e}")
        logger.error(
            f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {stock_info['éŠ˜æŸ„å']} ({ticker_symbol}) - çµ‚äº†æ™‚åˆ»: {end_datetime.strftime('%Y-%m-%d %H:%M:%S')} - å®Ÿè¡Œæ™‚é–“: {format_duration(duration)} - ã‚¨ãƒ©ãƒ¼: {e}"
        )
        return None


```

éƒ½é“åºœçœŒã‚’çŸ¥ã‚ŠãŸã‹ã£ãŸãŸã‚ã€yfinace ã§éƒµä¾¿ç•ªå·ãŒå–ã‚Œã‚‹ã®ã§ã€
éƒµä¾¿ç•ªå·ã‹ã‚‰éƒ½é“åºœçœŒã‚’å–å¾—ã™ã‚‹ã®ã«ã¯ã€

https://github.com/GitHub30/digital-address.php

ã“ã¡ã‚‰ã‚’ä½¿ã‚ã›ã¦ã„ãŸã ãã¾ã—ãŸã€‚ï¼ˆã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼ï¼‰

```python
def get_prefecture_from_zip(zip_code):
    """éƒµä¾¿ç•ªå·ã‹ã‚‰éƒ½é“åºœçœŒåã‚’å–å¾—ï¼ˆdigital-address APIä½¿ç”¨ï¼‰

    Args:
        zip_code (str): éƒµä¾¿ç•ªå·ï¼ˆãƒã‚¤ãƒ•ãƒ³ã‚ã‚Š/ãªã—ä¸¡æ–¹å¯¾å¿œï¼‰

    Returns:
        str: éƒ½é“åºœçœŒåï¼ˆä¾‹: "æ±äº¬éƒ½", "å¤§é˜ªåºœ"ï¼‰
        None: å–å¾—å¤±æ•—æ™‚ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ãªã—

    Note:
        - digital-address APIã‚’ä½¿ç”¨ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å–å¾—
        - éƒµä¾¿ç•ªå·ã®å‰å‡¦ç†ï¼ˆãƒã‚¤ãƒ•ãƒ³ãƒ»ç©ºç™½é™¤å»ï¼‰ã‚’è‡ªå‹•å®Ÿè¡Œ
        - ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š: 10ç§’
    """
    try:
        if not zip_code:
            return None

        # éƒµä¾¿ç•ªå·ã®å‰å‡¦ç†ï¼ˆãƒã‚¤ãƒ•ãƒ³ã‚„ç©ºç™½ã‚’é™¤å»ï¼‰
        clean_zip = str(zip_code).replace("-", "").replace("âˆ’", "").replace(" ", "").replace("ã€€", "")

        if len(clean_zip) < 7:  # éƒµä¾¿ç•ªå·ã¨ã—ã¦çŸ­ã™ãã‚‹å ´åˆ
            return None

        # digital-address APIã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        url = f"https://digital-address.app/{clean_zip}"

        response = requests.get(url, timeout=10)
        response.raise_for_status()

        data = response.json()

        if data.get("addresses") and len(data["addresses"]) > 0:
            # addressesã®æœ€åˆã®è¦ç´ ã‹ã‚‰pref_nameã‚’å–å¾—
            address = data["addresses"][0]
            prefecture = address.get("pref_name")
            logger.debug(f"  ğŸ¢ éƒ½é“åºœçœŒ: {prefecture}")
            return prefecture

        return None

    except Exception as e:
        logger.debug(f"    éƒµä¾¿ç•ªå·å¤‰æ›ã‚¨ãƒ©ãƒ¼ ({zip_code}): {e}")
        return None

```

## 3. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®å®Ÿè£…

:::note
å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚³ãƒ¼ãƒ‰ã‹ã‚‰æŠœç²‹ã—ã¦è¨˜è¼‰ã—ã¾ã™ã€‚
CSV ã®ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€æ•°åé …ç›®ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã€ãªã©ã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚
:::

### å…¨ä½“ã®çµ±åˆæ§‹é€ 

ã¾ãšã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“ã®æ§‹æˆã‚’æŠŠæ¡ã—ã¾ã—ã‚‡ã†ã€‚
ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸([DataPage.tsx](https://github.com/testkun08080/yfinance-jp-screener/blob/main/stock_search/src/pages/DataPage.tsx))ã§ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨ CSV ãƒ“ãƒ¥ãƒ¼ã‚¢ã‚’çµ±åˆã—ã¦ã„ã¾ã™ï¼š

```typescript
// pages/DataPage.tsxï¼ˆä¸»è¦éƒ¨åˆ†ã®æŠœç²‹ï¼‰
export const DataPage = () => {
  const [selectedFile, setSelectedFile] = useState<CSVFile | null>(null);
  const [uploadError, setUploadError] = useState<string | null>(null);

  const handleFileUpload = (file: File) => {
    setUploadError(null);

    // ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’CSVFileå½¢å¼ã«å¤‰æ›
    const uploadedCSVFile: CSVFile = {
      name: file.name,
      displayName: file.name,
      size: file.size,
      lastModified: new Date(file.lastModified).toISOString(),
      url: URL.createObjectURL(file), // ãƒ–ãƒ©ã‚¦ã‚¶ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ãŸã‚ã®URLç”Ÿæˆ
    };

    setSelectedFile(uploadedCSVFile);
  };

  return (
    <div className="container mx-auto px-4 py-6">
      {/* ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é ˜åŸŸ */}
      <FileUpload
        onFileSelect={handleFileUpload}
        loading={false}
        error={uploadError}
      />

      {/* CSVãƒ“ãƒ¥ãƒ¼ã‚¢ */}
      {selectedFile ? (
        <CSVViewer file={selectedFile} />
      ) : (
        <div className="card bg-base-100 shadow-sm">
          {/* ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼è¡¨ç¤º */}
        </div>
      )}
    </div>
  );
};
```

### 1. ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ— CSV ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

[FileUpload.tsx](https://github.com/testkun08080/yfinance-jp-screener/blob/main/stock_search/src/components/FileUpload.tsx)ã§ã¯ã€ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—ã¨ã‚¯ãƒªãƒƒã‚¯é¸æŠã®ä¸¡æ–¹ã«å¯¾å¿œã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¦ã¾ã™ã€‚

```typescript
// components/FileUpload.tsx
import React, { useRef } from "react";
import { CSV_FILE_CONFIG } from "../constants/csv";

interface FileUploadProps {
  onFileSelect: (file: File) => void;
  loading: boolean;
  error: string | null;
}

export const FileUpload: React.FC<FileUploadProps> = ({
  onFileSelect,
  loading,
  error,
}) => {
  const fileInputRef = useRef<HTMLInputElement>(null);

  // ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠï¼ˆã‚¯ãƒªãƒƒã‚¯çµŒç”±ï¼‰
  const handleFileChange = (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      onFileSelect(file);
    }
  };

  // ãƒ‰ãƒ©ãƒƒã‚°ã‚ªãƒ¼ãƒãƒ¼æ™‚ã®å‡¦ç†
  const handleDragOver = (event: React.DragEvent) => {
    event.preventDefault(); // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å‹•ä½œã‚’é˜²ã
  };

  // ãƒ‰ãƒ­ãƒƒãƒ—æ™‚ã®å‡¦ç†
  const handleDrop = (event: React.DragEvent) => {
    event.preventDefault();
    const file = event.dataTransfer.files[0];

    // CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å—ã‘ä»˜ã‘ã‚‹
    if (file && file.type === CSV_FILE_CONFIG.mimeType) {
      onFileSelect(file);
    }
  };

  const handleClick = () => {
    fileInputRef.current?.click();
  };

  return (
    <div className="bg-white rounded-lg shadow-sm p-6 mb-6">
      <h3 className="text-lg font-semibold text-base-content mb-4">
        CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
      </h3>

      <div
        className={`
          border-2 border-dashed rounded-lg p-8 text-center cursor-pointer
          transition-colors duration-200
          ${
            loading
              ? "border-gray-300 bg-gray-50"
              : "border-primary hover:border-primary-focus hover:bg-primary/5"
          }
        `}
        onDragOver={handleDragOver}
        onDrop={handleDrop}
        onClick={handleClick}
      >
        {/* éš ã—inputè¦ç´  */}
        <input
          ref={fileInputRef}
          type="file"
          accept={CSV_FILE_CONFIG.acceptAttribute}
          onChange={handleFileChange}
          className="hidden"
          disabled={loading}
        />

        {loading ? (
          // ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¡¨ç¤º
          <div className="flex flex-col items-center gap-3">
            <div className="loading loading-spinner loading-lg text-primary"></div>
            <p className="text-base-content/70">CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...</p>
          </div>
        ) : (
          // ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
          <div className="flex flex-col items-center gap-3">
            <div className="text-4xl text-primary">ğŸ“</div>
            <div>
              <p className="text-base-content font-medium mb-1">
                CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—
              </p>
              <p className="text-base-content/70 text-sm">
                ã¾ãŸã¯
                <span className="text-primary font-medium">
                  ã‚¯ãƒªãƒƒã‚¯ã—ã¦é¸æŠ
                </span>
              </p>
            </div>
            <div className="text-xs text-base-content/50">
              å¯¾å¿œå½¢å¼: CSV ({CSV_FILE_CONFIG.extension})
            </div>
          </div>
        )}
      </div>

      {/* ã‚¨ãƒ©ãƒ¼è¡¨ç¤º */}
      {error && (
        <div className="alert alert-error mt-4">
          <svg>...</svg>
          <span>{error}</span>
        </div>
      )}
    </div>
  );
};
```

### 2. CSV ãƒ‘ãƒ¼ã‚¹ã¨æ•°å€¤å‡¦ç†

[csvParser.ts](https://github.com/testkun08080/yfinance-jp-screener/blob/main/stock_search/src/utils/csvParser.ts)ã§ã¯ã€PapaParse ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦ CSV ãƒ‡ãƒ¼ã‚¿ã‚’è§£æã—ã€æ•°å€¤ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’é©åˆ‡ãªå‹ã«å¤‰æ›ã—ã¦ã¾ã™ã€‚

```typescript
// utils/csvParser.ts
import Papa from "papaparse";
import type { StockData } from "../types/stock";
import { CSV_PARSER_CONFIG, CSV_NUMERIC_FIELDS } from "../constants/csv";

export const parseCSVFile = (file: File): Promise<StockData[]> => {
  return new Promise((resolve, reject) => {
    Papa.parse(file, {
      header: CSV_PARSER_CONFIG.header, // 1è¡Œç›®ã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã—ã¦æ‰±ã†
      encoding: CSV_PARSER_CONFIG.encoding, // UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
      skipEmptyLines: CSV_PARSER_CONFIG.skipEmptyLines, // ç©ºè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—

      // ãƒ˜ãƒƒãƒ€ãƒ¼åã®å‰å‡¦ç†
      transformHeader: (header: string) => {
        return header.trim(); // å‰å¾Œã®ç©ºç™½ã‚’é™¤å»
      },

      // å„ã‚»ãƒ«ã®å€¤ã‚’å¤‰æ›
      transform: (value: string, header: string) => {
        // æ•°å€¤ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å ´åˆ
        if (
          CSV_NUMERIC_FIELDS.includes(
            header as (typeof CSV_NUMERIC_FIELDS)[number]
          )
        ) {
          // å˜ä½è¡¨è¨˜ã‚’é™¤å»ï¼ˆå€ã€%ã€å††ãªã©ï¼‰
          const cleanValue = value
            .replace(/,/g, "") // ã‚«ãƒ³ãƒé™¤å»
            .replace(/å€$/, "") // ã€Œå€ã€é™¤å»
            .replace(/%$/, "") // ã€Œ%ã€é™¤å»
            .replace(/å††$/, "") // ã€Œå††ã€é™¤å»
            .trim();

          const numValue = parseFloat(cleanValue);
          return isNaN(numValue) ? null : numValue;
        }

        // æ–‡å­—åˆ—ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å ´åˆ
        return value.trim() || null;
      },

      // ãƒ‘ãƒ¼ã‚¹å®Œäº†æ™‚
      complete: (results) => {
        if (results.errors.length > 0) {
          console.error("CSV parsing errors:", results.errors);
          reject(new Error("CSVãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"));
          return;
        }

        try {
          const stockData = results.data as StockData[];
          // ä¼šç¤¾åã¨éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ãŒå­˜åœ¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
          resolve(stockData.filter((row) => row.ä¼šç¤¾å && row.éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰));
        } catch (error) {
          reject(new Error("ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"));
        }
      },

      // ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼æ™‚
      error: (error: Error) => {
        reject(
          new Error(`CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: ${error.message}`)
        );
      },
    });
  });
};

// æ•°å€¤ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆæ—¥æœ¬èªãƒ­ã‚±ãƒ¼ãƒ«å¯¾å¿œï¼‰
export const formatNumber = (value: number | null, decimals = 0): string => {
  if (value === null || value === undefined) return "-";
  return value.toLocaleString("ja-JP", {
    minimumFractionDigits: decimals,
    maximumFractionDigits: decimals,
  });
};

// é€šè²¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆç™¾ä¸‡å††å˜ä½ï¼‰
export const formatCurrency = (value: number | null): string => {
  if (value === null || value === undefined) return "-";

  // ç™¾ä¸‡å††å˜ä½ã§è¡¨ç¤º
  return formatNumber(value / 1000000, 0);
};

// ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
export const formatPercentage = (value: number | null): string => {
  if (value === null || value === undefined) return "-";
  return `${formatNumber(value * 100, 2)}%`;
};
```

### 3. ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½

[useFilters.ts](https://github.com/testkun08080/yfinance-jp-screener/blob/main/stock_search/src/hooks/useFilters.ts)ã§ã¯ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã‚’ç®¡ç†ã—ã€useMemo ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†ã—ã¦ã¾ã™ã€‚

```typescript
// hooks/useFilters.tsï¼ˆä¸»è¦éƒ¨åˆ†ã®æŠœç²‹ï¼‰
import { useState, useMemo } from "react";
import type { StockData, SearchFilters } from "../types/stock";

const initialFilters: SearchFilters = {
  companyName: "",
  stockCode: "",
  industries: [],
  market: [],
  prefecture: [],
  marketCapMin: null,
  marketCapMax: null,
  pbrMin: null,
  pbrMax: null,
  roeMin: null,
  roeMax: null,
  // ... è¨ˆ23é …ç›®ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
};

export const useFilters = (data: StockData[]) => {
  const [filters, setFilters] = useState<SearchFilters>(initialFilters);
  const [sortConfig, setSortConfig] = useState<SortConfig | null>(null);

  // ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†ï¼ˆuseMemoã§æœ€é©åŒ–ï¼‰
  const filteredData = useMemo(() => {
    const filtered = data.filter((stock) => {
      // 1. ä¼šç¤¾åãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆéƒ¨åˆ†ä¸€è‡´ã€å¤§æ–‡å­—å°æ–‡å­—åŒºåˆ¥ãªã—ï¼‰
      if (
        filters.companyName &&
        !stock.ä¼šç¤¾å?.toLowerCase().includes(filters.companyName.toLowerCase())
      ) {
        return false;
      }

      // 2. éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰
      if (filters.stockCode) {
        const stockCode = stock.éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ || stock.ã‚³ãƒ¼ãƒ‰ || "";
        if (!stockCode.toString().includes(filters.stockCode)) {
          return false;
        }
      }

      // 3. æ¥­ç¨®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆè¤‡æ•°é¸æŠå¯¾å¿œï¼‰
      if (
        filters.industries.length > 0 &&
        !filters.industries.includes(stock.æ¥­ç¨® || "")
      ) {
        return false;
      }

      // 4. å¸‚å ´ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆè¤‡æ•°é¸æŠå¯¾å¿œï¼‰
      if (
        filters.market.length > 0 &&
        !filters.market.includes(stock.å„ªå…ˆå¸‚å ´ || "")
      ) {
        return false;
      }

      // 5. éƒ½é“åºœçœŒãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆè¤‡æ•°é¸æŠå¯¾å¿œï¼‰
      if (
        filters.prefecture.length > 0 &&
        !filters.prefecture.includes(stock.éƒ½é“åºœçœŒ || "")
      ) {
        return false;
      }

      // 6. PBRç¯„å›²ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆnull/undefinedå¯¾å¿œï¼‰
      if (
        filters.pbrMin !== null &&
        stock.PBR !== null &&
        stock.PBR !== undefined &&
        typeof stock.PBR === "number" &&
        stock.PBR < filters.pbrMin
      ) {
        return false;
      }
      if (
        filters.pbrMax !== null &&
        stock.PBR !== null &&
        stock.PBR !== undefined &&
        typeof stock.PBR === "number" &&
        stock.PBR > filters.pbrMax
      ) {
        return false;
      }

      // 7. ROEç¯„å›²ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆå¤‰æ›å¯¾å¿œï¼‰
      if (
        filters.roeMin !== null &&
        stock.ROE !== null &&
        stock.ROE !== undefined &&
        typeof stock.ROE === "number" &&
        stock.ROE < filters.roeMin / 100 // UIã¯%ã€ãƒ‡ãƒ¼ã‚¿ã¯å°æ•°ãªã®ã§å¤‰æ›
      ) {
        return false;
      }
      if (
        filters.roeMax !== null &&
        stock.ROE !== null &&
        stock.ROE !== undefined &&
        typeof stock.ROE === "number" &&
        stock.ROE > filters.roeMax / 100
      ) {
        return false;
      }

      // 8. æ™‚ä¾¡ç·é¡ç¯„å›²ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆç™¾ä¸‡å††å˜ä½ã‹ã‚‰ã®å¤‰æ›ï¼‰
      if (
        filters.marketCapMin !== null &&
        stock.æ™‚ä¾¡ç·é¡ !== null &&
        stock.æ™‚ä¾¡ç·é¡ !== undefined &&
        typeof stock.æ™‚ä¾¡ç·é¡ === "number" &&
        stock.æ™‚ä¾¡ç·é¡ < filters.marketCapMin * 1000000 // UIå…¥åŠ›ã¯ç™¾ä¸‡å††å˜ä½
      ) {
        return false;
      }
      if (
        filters.marketCapMax !== null &&
        stock.æ™‚ä¾¡ç·é¡ !== null &&
        stock.æ™‚ä¾¡ç·é¡ !== undefined &&
        typeof stock.æ™‚ä¾¡ç·é¡ === "number" &&
        stock.æ™‚ä¾¡ç·é¡ > filters.marketCapMax * 1000000
      ) {
        return false;
      }

      // ... ä»–ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ï¼ˆå£²ä¸Šé«˜ã€å–¶æ¥­åˆ©ç›Šã€è‡ªå·±è³‡æœ¬æ¯”ç‡ãªã©ï¼‰

      return true; // ã™ã¹ã¦ã®æ¡ä»¶ã‚’æº€ãŸã™å ´åˆã®ã¿true
    });

    // ã‚½ãƒ¼ãƒˆå‡¦ç†
    if (sortConfig) {
      filtered.sort((a, b) => {
        const aValue = a[sortConfig.key];
        const bValue = b[sortConfig.key];

        // nullå€¤ã®å‡¦ç†ï¼ˆnullã¯æœ€å¾Œã«é…ç½®ï¼‰
        if (aValue === null && bValue === null) return 0;
        if (aValue === null) return 1;
        if (bValue === null) return -1;

        let result = 0;
        if (typeof aValue === "string" && typeof bValue === "string") {
          result = aValue.localeCompare(bValue, "ja-JP"); // æ—¥æœ¬èªå¯¾å¿œã‚½ãƒ¼ãƒˆ
        } else if (typeof aValue === "number" && typeof bValue === "number") {
          result = aValue - bValue;
        }

        return sortConfig.direction === "desc" ? -result : result;
      });
    }

    return filtered;
  }, [data, filters, sortConfig]);

  // ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ›´æ–°é–¢æ•°
  const updateFilter = (
    key: keyof SearchFilters,
    value: string | number | string[] | null
  ) => {
    const newFilters = {
      ...filters,
      [key]: value,
    };
    setFilters(newFilters);
  };

  // ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚¯ãƒªã‚¢
  const clearFilters = () => {
    setFilters(initialFilters);
  };

  return {
    filters,
    filteredData,
    sortConfig,
    updateFilter,
    clearFilters,
  };
};
```

## 4. Docker ç’°å¢ƒã®æ§‹ç¯‰

### Dockerfile.fetch

ã‚·ãƒ³ãƒ—ãƒ«ã«ãƒ­ãƒ¼ã‚«ãƒ«ã«ã‚ã‚‹è¨­å®šã‚’ä½¿ã£ã¦ã€ã‚³ãƒ³ãƒ†ãƒŠå†…ã§ãƒ‡ãƒ¼ã‚¿åé›†ã‚’ã“ãªã„ãƒ­ãƒ¼ã‚«ãƒ«ã«åŒæœŸã•ã›ã¾ã™ã€‚

```yaml
# Python Data Collection Service Dockerfile
# æ ªå¼ãƒ‡ãƒ¼ã‚¿åé›†ã‚µãƒ¼ãƒ“ã‚¹ç”¨Dockerfile

FROM python:3.11-slim

# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
WORKDIR /app

# ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æ›´æ–°ã¨å¿…è¦ãªãƒ„ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Pythonã®ä¾å­˜é–¢ä¿‚ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
COPY stock_list/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# æ ªå¼ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ã‚³ãƒ”ãƒ¼
COPY stock_list/*.py ./
COPY stock_list/stocks_sample.json ./

# ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
RUN mkdir -p Export

# érootãƒ¦ãƒ¼ã‚¶ãƒ¼ã§å®Ÿè¡Œ
RUN useradd -m -u 1000 stockuser && \
    chown -R stockuser:stockuser /app
USER stockuser

# ç’°å¢ƒå¤‰æ•°ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
ENV STOCK_FILE=stocks_sample.json
ENV CHUNK_SIZE=1000

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚³ãƒãƒ³ãƒ‰ï¼ˆæ ªå¼ãƒªã‚¹ãƒˆå–å¾— â†’ åˆ†å‰² â†’ ãƒ‡ãƒ¼ã‚¿åé›†ï¼‰
# ç’°å¢ƒå¤‰æ•°ã‚’ä½¿ç”¨ã—ã¦å‹•çš„ã«è¨­å®š
CMD ["sh", "-c", "python get_jp_stocklist.py && python split_stocks.py --input stocks_all.json --size ${CHUNK_SIZE} && python sumalize.py ${STOCK_FILE} && python combine_latest_csv.py"]
```

### Dockerfile.app

è‡³ã£ã¦ã‚·ãƒ³ãƒ—ãƒ«ãªã‚‚ã®ã§ã™ã€‚
ãƒ“ãƒ«ãƒ‰ã—ãŸã‚‚ã®ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã§ã‚µãƒ¼ãƒ–ã™ã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

```yaml
# React Frontend Service Dockerfile
# ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒ“ãƒ«ãƒ‰ãƒ»æœ¬ç•ªã‚µãƒ¼ãƒ“ã‚¹ç”¨Dockerfile

FROM node:20-alpine AS base

# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
WORKDIR /app

# ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–ï¼‰
FROM base AS deps
COPY stock_search/package*.json ./
RUN npm ci

# ãƒ“ãƒ«ãƒ‰ã‚¹ãƒ†ãƒ¼ã‚¸
FROM base AS builder
COPY stock_search/package*.json ./
COPY --from=deps /app/node_modules ./node_modules
COPY stock_search/ .

# TypeScriptã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã¨Viteãƒ“ãƒ«ãƒ‰
RUN npm run build --loglevel=info

# æœ¬ç•ªç’°å¢ƒã‚¹ãƒ†ãƒ¼ã‚¸ï¼ˆnginxä½¿ç”¨ï¼‰
FROM nginx:alpine AS runner

# nginxã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
COPY --from=builder /app/nginx.conf /etc/nginx/conf.d/default.conf

# ãƒ“ãƒ«ãƒ‰æˆæœç‰©ã®ã¿ã‚’ã‚³ãƒ”ãƒ¼
COPY --from=builder /app/dist /usr/share/nginx/html

# ãƒãƒ¼ãƒˆå…¬é–‹ï¼ˆnginx ã¯ 80 ã§å¾…å—ï¼‰
EXPOSE 80

# nginxèµ·å‹•
CMD ["nginx", "-g", "daemon off;"]

```

### docker-compose

ä¸Šè¨˜ Dockerfile ã‚’ã¾ã¨ã‚ãŸ compose ã§ã™ã€‚

```yaml
vservices:
  # Pythonãƒ‡ãƒ¼ã‚¿åé›†ã‚µãƒ¼ãƒ“ã‚¹
  python-service:
    build:
      context: .
      dockerfile: Dockerfile.fetch
    container_name: stock-data-collector
    env_file:
      - .env
    volumes:
      # æ ªå¼ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒã‚¦ãƒ³ãƒˆ
      - ./stock_list:/app:rw
      # Exportãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å…±æœ‰
      - ./stock_list/Export:/app/Export:rw
    environment:
      - PYTHONUNBUFFERED=1
      - STOCK_FILE=${STOCK_FILE:-stocks_sample.json}
      - CHUNK_SIZE=${CHUNK_SIZE:-1000}
    restart: "no"

  # React ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹
  frontend-service:
    build:
      context: .
      dockerfile: Dockerfile.app
    container_name: stock-frontend
    env_file:
      - .env
    ports:
      - "${PORT}:80"
    environment:
      - NODE_ENV=${NODE_ENV:-production}
    command: >
      sh -c "echo 'Frontend running on http://localhost:${PORT}' && nginx -g 'daemon off;'"
```

# ä½¿ã„æ–¹

## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆï¼ˆDockerï¼‰

### äº‹å‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ãªã‚‚ã®

- [Docker](https://docs.docker.com/get-started/get-docker/)

```bash
# ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/testkun08080/yfinance-jp-screener.git
cd yfinance-jp-screener

cp .env.example .env
# STOCK_FILEã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯"stocks_sample.json"ã«ãªã£ã¦ã„ã¾ã™ã€‚ å¿…ãšå…¨ã¦å–å¾—ã—ãŸã„å ´åˆã¯"stocks_all.json"ã¸å¤‰ãˆã¦ä¸‹ã•ã„

# Dockerèµ·å‹•ï¼ˆãƒ‡ãƒ¼ã‚¿åé›† â†’ ãƒ“ãƒ«ãƒ‰ â†’ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰

# ã“ã‚Œã§pythonã¨ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãŒèµ·å‹•ã—ã¾ã™ï¼ˆpythonã¯è£ã§å‹•ãç¶šã‘ã‚‹ã®ã§ã€çµ‚ã‚ã£ãŸã‚‰stock_list/Exportä»¥ä¸‹ã«ã‚ã‚‹csvã‚’ä½¿ã£ã¦ä¸‹ã•ã„ï¼‰
docker-compose up

# # ğŸ“¦ Python ãƒ‡ãƒ¼ã‚¿åé›†ãƒ“ãƒ«ãƒ‰ãƒ»å®Ÿè¡Œ
# docker-compose build python-service
# docker-compose run --rm python-service

# # ğŸŒ ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒ“ãƒ«ãƒ‰ãƒ»èµ·å‹•
# docker-compose build frontend-service
# docker-compose up frontend-service

# ãƒ–ãƒ©ã‚¦ã‚¶ã§ã‚¢ã‚¯ã‚»ã‚¹(ç’°å¢ƒå¤‰æ•°ã®PORTç•ªå·ã«ã‚ˆã‚Šã¾ã™)
open http://localhost:8000

```

**åˆå›èµ·å‹•æ™‚ã®æ³¨æ„:**
ãƒ‡ãƒ¼ã‚¿åé›†ã«ç´„ 4 æ™‚é–“ã‹ã‹ã‚Šã¾ã™ï¼ˆç´„ 3,795 ç¤¾ï¼‰ã€‚

## ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã®å®Ÿè¡Œ

### äº‹å‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ãªã‚‚ã®

- [UV](https://docs.astral.sh/uv/getting-started/installation/)
- [nodejs](https://nodejs.org/en/download)

#### ãƒ‡ãƒ¼ã‚¿å–å¾—ç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# 1. ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/yourusername/yfinance-jp-screener.git
cd yfinance-jp-screener/stock_list

# 2. Pythonç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆuvã‚’ä½¿ç”¨ï¼‰
uv sync

# 3. æ ªå¼ãƒªã‚¹ãƒˆå–å¾—ï¼ˆåˆå›ã®ã¿ï¼‰
uv run get_jp_stocklist.py

# 4. ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’å®Ÿè¡Œ
uv run sumalize.py stocks_sample.json   #ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆç”¨

#===ç´„1000ç¤¾ãšã¤ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰(æ¨å¥¨)===
# uv run sumalize.py stocks_1.json
# uv run sumalize.py stocks_2.json
# uv run sumalize.py stocks_3.json
# uv run sumalize.py stocks_4.json

#===ã™ã¹ã¦ã®éŠ˜æŸ„ã‚’å¯¾è±¡ã«ã—ãŸãƒ€ã‚¦ãƒ­ãƒ¼ãƒ‰===
# uv run sumalize.py stocks_all.json

# 6. CSVçµåˆ
uv run combine_latest_csv.py
```

#### ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# 1. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ç§»å‹•
cd ../stock_search

# 2. ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
npm install

# 3. é–‹ç™ºã‚µãƒ¼ãƒãƒ¼èµ·å‹•
npm run dev
# http://localhost:5173/ ã«ã‚¢ã‚¯ã‚»ã‚¹

# ã¾ãŸã¯ã€æœ¬ç•ªãƒ“ãƒ«ãƒ‰å¾Œã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
npm run build
npm run preview
# http://localhost:4173/ ã«ã‚¢ã‚¯ã‚»ã‚¹

```

---

### GitHub Actions ã§ã®è‡ªå‹•åé›†

:::note
**é‡è¦**: GitHub Actions ã‚’ä½¿ç”¨ã™ã‚‹å‰ã«ã€ä»¥ä¸‹ã®è¨­å®šãŒå¿…è¦ã§ã™ï¼š

ãƒªãƒã‚¸ãƒˆãƒªã® **Settings** â†’ **Actions** â†’ **General** ã«ç§»å‹•

- âœ… **"Read and write permissions"** ã‚’é¸æŠ
- âœ… **"Allow GitHub Actions to create and approve pull requests"** ã«ãƒã‚§ãƒƒã‚¯

ã“ã®è¨­å®šã«ã‚ˆã‚Šã€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒç”Ÿæˆã—ãŸ CSV ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒªãƒã‚¸ãƒˆãƒªã«ã‚³ãƒŸãƒƒãƒˆã§ãã¾ã™ã€‚
:::

**å®Ÿè¡Œæ‰‹é †:**

1. ãƒªãƒã‚¸ãƒˆãƒªã‚’**ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆ**ã§ãƒ•ã‚©ãƒ¼ã‚¯
2. Settings â†’ Actions ã§ä¸Šè¨˜æ¨©é™ã‚’è¨­å®š
3. Actions â†’ "Stock List Update" ã‚’å®Ÿè¡Œã—ã¦æ–°ã—ã„ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚·ãƒ³ãƒœãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—
4. Actions â†’ "ğŸ“Š Sequential Stock Fetch - Part 1" ã‚’å®Ÿè¡Œ
5. è‡ªå‹•é€£é–å®Ÿè¡Œï¼ˆPart 1 â†’ Part 2 â†’ Part 3 â†’ Part 4 â†’ CSV Combineï¼‰
6. ç´„ 3ã€œ4 æ™‚é–“å¾Œã«å…¨ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†
7. `stock_list/Export/YYYYMMDD_combined.csv` ã«çµåˆæ¸ˆã¿ CSV ãŒç”Ÿæˆã•ã‚Œã‚‹

**ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ§‹æˆ:**

- `stock-list-update.yml` - JPX æ ªå¼ãƒªã‚¹ãƒˆæ›´æ–°ç”¨
- `stock-fetch-sequential-1~4.yml` - 4 æ®µéšãƒ‡ãƒ¼ã‚¿åé›†ï¼ˆå„ 120 åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰
- `csv-combine-export.yml` - CSV çµåˆå‡¦ç†

# é‡è¦ãªæ³¨æ„äº‹é …

## âš ï¸ ãƒ‡ãƒ¼ã‚¿ã®å–ã‚Šæ‰±ã„ã«ã¤ã„ã¦

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯**å€‹äººåˆ©ç”¨ãƒ»ç ”ç©¶ãƒ»æ•™è‚²ç›®çš„**ã§ã®ã¿ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

:::note alert
**ãƒ‡ãƒ¼ã‚¿ã®å–ã‚Šæ‰±ã„ã¯ä»¥ä¸‹ã‚’å‚ç…§ãã ã•ã„**

1. Yahoo! Finance Terms of Service
   https://legal.yahoo.com/us/en/yahoo/terms/otos/index.html

2. Yahoo! Developer API Terms of Use
   https://policies.yahoo.com/us/en/yahoo/terms/product-atos/apiforydn/index.htm

3. Yahoo! æ¨©åˆ©é–¢ä¿‚ãƒšãƒ¼ã‚¸
   https://legal.yahoo.com/us/en/yahoo/permissions/requests/index.html

:::

- API ã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’å®ˆã‚Šã€éåº¦ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯é¿ã‘ã¦ãã ã•ã„
- å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã®æ­£ç¢ºæ€§ã¯ä¿è¨¼ã•ã‚Œã¾ã›ã‚“

## å‚è€ƒãƒªãƒ³ã‚¯

- [yfinance GitHub Repository](https://github.com/ranaroussi/yfinance)
- [Yahoo Finance](https://finance.yahoo.com/)
- [æ—¥æœ¬å–å¼•æ‰€ã‚°ãƒ«ãƒ¼ãƒ—ï¼ˆJPXï¼‰](https://www.jpx.co.jp/)
- [ã‚ãŒæŠ•è³‡è¡“ï¼ˆAmazonï¼‰](https://amzn.to/3IEVRkq)

---

## ãƒã‚¤ãƒ–ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è¡Œã†å‰ã«ã‚„ã£ãŸã“ã¨

å¤§ä½“ã®æ–¹ã€…ãŒåŒã˜ã‚„ã‚Šæ–¹ã ã¨æ€ã„ã¾ã™ãŒã€åƒ•ã¯ã“ã‚“ãªæ„Ÿã˜ã§ã™ã€‚

- ã–ã£ãã‚Šã®æµã‚Œã‚’ AI(å¤šåˆ†ä½•ã§ã‚‚è‰¯ã„)ã«æ¸¡ã™
- è³ªå•å½¢å¼ã§ã™ã‚Šåˆã‚ã›ã™ã‚‹
- ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¾ã¨ã‚ã¦ã‚‚ã‚‰ã£ã¦ã€Claude ã«æ¸¡ã™
- Claude ã«æ¸¡ã™ã¨ãã«ã€ã‚‚ã†ä¸€åº¦èª­è§£ã•ã›ã¦ã€ã™ã‚Šåˆã‚ã›ã‚‹
- å®Ÿè¡Œ

## ãã®ä»–

ã‚‚ã—ã“ã®è¨˜äº‹ãŒå½¹ç«‹ã£ãŸã‚‰ã€[ã‚³ãƒ¼ãƒ’ä¸€æ¯ã»ã©](https://buymeacoffee.com/testkun08080)ã‚‚ã‚‰ãˆã‚‹ã¨æœ€é«˜ã§ã™

æœ€å¾Œã¾ã§ãŠèª­ã¿ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚
ä½•ã‹ãŠã‹ã—ã„ã¨ã‹ã€ã‚‚ã£ã¨ã“ã†ã—ãŸæ–¹ãŒã„ã„ã¨ã‹ã‚ã‚Œã° issue ã‚„ã‚³ãƒ¡ãƒ³ãƒˆã§ãŠå¾…ã¡ã—ã¦ã„ã¾ã™ã€‚

sakana-ai ãŒæ›¸ã„ã¦ã„ãŸ**EDINET**ã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œã‚‹ã„ã„æ„Ÿã˜ã®ãƒ¬ãƒã‚‚è¦‹ã¤ã‘ãŸã®ã§ã€ã“ã‚Œã‚’ yfinance ã®ä»£ã‚ã‚Šã¨ã™ã‚‹ã®ã‚‚ã®ã„ã„ã®ã‹ãªãã¨ã‚‚æ€ã„ã¾ã™ã€‚ï¼ˆãŠãã‚‰ãã“ã‚Œãªã‚‰ã€ãƒ‡ãƒ¼ã‚¿ã®é–‹ç¤ºã«ã¤ã„ã¦ã¯å•é¡Œãªã„ï¼‰
æ™‚é–“è¦‹ã¤ã‘ãŸã‚‰ã€ã‚„ã£ã¦ã¿ã‚ˆã†ã‹ãªãã¨æ€ã„ã¾ã™ã€‚

èˆˆå‘³ãŒã‚ã‚‹æ–¹ã¯ã€ä»¥ä¸‹ã®ãƒ¬ãƒã‚’ã”è¦§ãã ã•ã„ã€‚
https://github.com/SakanaAI/edinet2dataset

ãã‚Œã§ã¯ ğŸ™

**å…è²¬äº‹é …:**
æŠ•è³‡åˆ¤æ–­ã¯è‡ªå·±è²¬ä»»ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
